{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study: Lorenz attractor\n",
    "##### License: Apache 2.0\n",
    "\n",
    "\n",
    "This notebook contains a full TDA pipeline to analyse the transitions of the Lorenz system to a chaotic regime from the stable one and viceversa.\n",
    "\n",
    "The first step consists in importing the *giotto* library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the giotto library\n",
    "import giotto as go\n",
    "import giotto.datasets as ds\n",
    "import giotto.time_series as ts\n",
    "import giotto.graphs as gr\n",
    "import giotto.diagram as diag\n",
    "import giotto.homology as hl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sklearn as sk\n",
    "from giotto.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objs as gobj\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Lorenz attractor simulation\n",
    "\n",
    "In the next block we set up all the parameters of the Lorenz system and we define also the instants at which the regime (stable VS chaotic) changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 5000\n",
    "transition_list = [0.037500000000000006, 0.047, 0.0625, 0.077, 0.10350000000000001, 0.1275, 0.1585, 0.1615, \n",
    "                  0.1685, 0.2215, 0.23, 0.23700000000000002, 0.2515, 0.2715, 0.3, 0.30750000000000005, 0.3385, \n",
    "                  0.36350000000000005, 0.388, 0.40449999999999997, 0.41950000000000004, 0.4225, 0.4515, \n",
    "                  0.46950000000000003, 0.506, 0.5405, 0.542, 0.5825, 0.5825, 0.6144999999999999, 0.635, 0.66, \n",
    "                  0.677, 0.6845, 0.685, 0.729, 0.749, 0.769, 0.777, 0.8075, 0.8310000000000001, 0.833, 0.864, \n",
    "                  0.8674999999999999, 0.882, 0.903, 0.9395, 0.94, 0.974, 0.99]\n",
    "\n",
    "# Method to generate a solution of the Lorenz system\n",
    "lorenz_attractor = ds.LorenzDataset(initial_conditions=(1, -10, 10), sigma=10., beta=8./3., rho_min=5, rho_max=15,\n",
    "                     transition_list=transition_list, number_transitions=25, transition_duration=100,\n",
    "                     time_step=0.01, max_duration=max_duration, mean_noise=0., std_deviation_noise=0.0)\n",
    "lorenz_attractor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the trajectories of the Lorenz system\n",
    "trace = gobj.Scatter3d(x=lorenz_attractor.x_, y=lorenz_attractor.y_, z=lorenz_attractor.z_, mode='markers',\n",
    "                       marker=dict(size=4, color=list(range(max_duration)),\n",
    "                       colorscale='Viridis', opacity=0.8))\n",
    "\n",
    "data = [trace]\n",
    "layout = gobj.Layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "\n",
    "figure = gobj.Figure(data=data, layout=layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lorenz_attractor.z_.reshape(-1, 1)\n",
    "y = lorenz_attractor.rho_\n",
    "\n",
    "# Plotting the Lorenz system\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X)\n",
    "plt.plot(y)\n",
    "plt.title('Trajectory of the Lorenz solution, projected along the z-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling the time series\n",
    "\n",
    "It is important to find the correct time scale at which key signals take place. Here we propose one possible resampling period: *10h*. Recall that the unit time is *1h*. The resampler method is used to perform the resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 10\n",
    "periodicSampler = ts.Resampler(period=period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodicSampler.fit(X)\n",
    "X_sampled, y_sampled = periodicSampler.transform_resample(X, y)\n",
    "\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_sampled)\n",
    "plt.plot(y_sampled)\n",
    "plt.title('Trajectory of the Lorenz solution, projected along the z-axis and resampled every 10h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps of the Pipeline\n",
    "steps = [\n",
    "    ('sampling', ts.Resampler(period=period)),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100))\n",
    "]\n",
    "\n",
    "# Sklearn Pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takens Embedding\n",
    "\n",
    "In order to obtain meaningful topological features from a time series, we use a delayed-time embedding technique, invented by F. Takens in the late sixties.\n",
    "The idea is simple: given a time series X(t), one can extract a sequence of vectors of the form X_i := [(X(t_i)), X(t_i + 2 tau), ..., X(t_i + M tau)].\n",
    "The difference between t_i and t_i-1 is called *stride*; the numbers M and tau are optimized authomatically in this example (they can be set by the user if needed).\n",
    "    \n",
    "The *outer window* allows us to apply Takens embedding locally on a certain interval rather than over the whole time series. The result of this procedure is therefore a time series of point clouds with possibly interesting topologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 10\n",
    "embedding_time_delay = 3\n",
    "embedder = ts.TakensEmbedder(parameters_type='search', dimension=embedding_dimension, \n",
    "                             time_delay=embedding_time_delay, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.fit(X)\n",
    "embedder_time_delay = embedder.time_delay_\n",
    "embedder_dimension = embedder.dimension_\n",
    "\n",
    "print('Optimal embedding time delay based on mutual information: ', embedder_time_delay)\n",
    "print('Optimal embedding dimension based on false nearest neighbors: ', embedder_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded, y_embedded = embedder.transform_resample(X_sampled, y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width = 40\n",
    "window_stride = 5\n",
    "sliding_window = ts.SlidingWindow(width=window_width, stride=window_stride)\n",
    "sliding_window.fit(X_embedded, y_embedded)\n",
    "\n",
    "X_windows, y_windows = sliding_window.transform_resample(X_embedded, y_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Takens embedding of the first outer window\n",
    "window = X_windows[window_number]\n",
    "trace = gobj.Scatter3d(x=window[:, 0], y=window[:, 1], z=window[:, 2], mode='markers',\n",
    "                     marker=dict(size=4, color=list(range(window.shape[0])),\n",
    "                     colorscale='Viridis', opacity=0.8))\n",
    "\n",
    "data = [trace]\n",
    "layout = gobj.Layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "\n",
    "figure = gobj.Figure(data=data, layout=layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time series associated to the above point cloud. \n",
    "# Notice the two periodicities corresponding to the loops in the embedding\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_sampled[(window_number*window_stride)*embedder_time_delay*embedder_dimension:\n",
    "                   (window_number*window_stride + window_width)*embedder_time_delay*embedder_dimension])\n",
    "plt.title('The Lorenz solution over one outer window ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence diagram\n",
    "The topological information of the correlation metric is synthesised in the persistent diagram. The horizonral axis corresponds to the moment in which an homological generator is born, while the vertical axis corresponds to the moments in which an homological generator dies.\n",
    "The generators of the homology groups (at given rank) are colored differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homology_dimensions = [0, 1, 2]\n",
    "persistenceDiagram = hl.VietorisRipsPersistence(metric='euclidean', max_edge_length=100, \n",
    "                                            homology_dimensions=homology_dimensions, n_jobs=1)\n",
    "persistenceDiagram.fit(X_windows)\n",
    "X_diagrams = persistenceDiagram.transform(X_windows, y_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "diagram = X_diagrams[window_number]\n",
    "print(sorted(list(set(diagram[:, 2]))))\n",
    "for dimension in homology_dimensions:\n",
    "    plt.plot(diagram[diagram[:,2] == dimension][:,0], \n",
    "             diagram[diagram[:,2] == dimension][:,1], 'o',label='homology '+ str(dimension))\n",
    "plt.title('Persistent Diagram')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 14], [0, 14], color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding gaussian noise\n",
    "\n",
    "It is claimed in the literature that TDA is robust with respect to noise. Let us then add noise to the system and redo the previous analysis and see what changes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_attractor.stdDeviationNoise = 0.3\n",
    "lorenz_attractor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy = lorenz_attractor.z_.reshape(-1, 1)\n",
    "y_noisy = lorenz_attractor.rho_\n",
    "\n",
    "# Plotting the Lorenz system\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_noisy)\n",
    "plt.plot(y_noisy)\n",
    "plt.title('Trajectory of the Lorenz solution, projected along the z-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn *Pipeline*\n",
    "One of the advantages of our giotto library is the compatibility with scikit-learn. It is possible to set up a full pipeline such as the one above in a few lines. We will show how in the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps of the Pipeline\n",
    "steps = [\n",
    "    ('sampling', ts.Resampler(period=period)),\n",
    "    ('embedding', ts.TakensEmbedder(parameters_type='search', dimension=embedding_dimension, \n",
    "                                    time_delay=embedding_time_delay, n_jobs=-1)),\n",
    "    ('window', ts.SlidingWindow(width=window_width, stride=window_stride)),\n",
    "    ('diagrams', hl.VietorisRipsPersistence(metric='euclidean', max_edge_length=100, \n",
    "                                            homology_dimensions=homology_dimensions, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Sklearn Pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the pipeline\n",
    "pipeline.fit(X_noisy)\n",
    "X_diagrams_noisy = pipeline.transform(X_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the final persistent diagram of one outer window\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "diagram = X_diagrams_noisy[window_number]\n",
    "\n",
    "for dimension in homology_dimensions:\n",
    "    plt.plot(diagram[diagram[:,2] == dimension][:,0], \n",
    "             diagram[diagram[:,2] == dimension][:,1], 'o',label='homology '+ str(dimension))\n",
    "plt.title('Persistent Diagram')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 22], [0, 22], color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescaling the diagram\n",
    "Rescaling the diagram means normalizing the points such that their distance from the *empty diagram* is equal to one.\n",
    "Once the diagram is rescaled, we can filter noise by removing all the points that are close to the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram_scaler = diag.DiagramScaler()\n",
    "diagram_scaler.fit(X_diagrams_noisy)\n",
    "X_scaled_noisy = diagram_scaler.transform(X_diagrams_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "diagram = X_scaled_noisy[window_number]\n",
    "\n",
    "for dimension in homology_dimensions:\n",
    "    plt.plot(diagram[diagram[:,2] == dimension][:,0], \n",
    "             diagram[diagram[:,2] == dimension][:,1], 'o',label='homology '+ str(dimension))\n",
    "plt.title('Persistent Diagram')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 2], [0, 2], color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering diagrams\n",
    "\n",
    "Filtering noise from a diagram corresponds to eliminating all the homology generators whose lifespan is too short to be significant. It means equivalently that we are removing the points closer to the diagonal than a centrain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perparing the filtering transformer\n",
    "diagram_filter = diag.DiagramFilter(delta=0.1, homology_dimensions=[1, 2])\n",
    "diagram_filter.fit(X_scaled_noisy)\n",
    "X_filtered_noisy = diagram_filter.transform(X_scaled_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "diagram = X_filtered_noisy[window_number]\n",
    "\n",
    "for dimension in homology_dimensions:\n",
    "    plt.plot(diagram[diagram[:,2] == dimension][:,0], \n",
    "             diagram[diagram[:,2] == dimension][:,1], 'o',label='homology '+ str(dimension))\n",
    "plt.title('Persistent Diagram')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 2], [0, 2], color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping up all the steps inside a scikit-learn pipeline\n",
    "steps = [\n",
    "    ('sampling', ts.Resampler(period=period)),\n",
    "    ('embedding', ts.TakensEmbedder(parameters_type='search', dimension=embedding_dimension, \n",
    "                                    time_delay=embedding_time_delay, n_jobs=1)),\n",
    "    ('window', ts.SlidingWindow(width=window_width, stride=window_stride)),\n",
    "    ('diagrams', hl.VietorisRipsPersistence(metric='euclidean', max_edge_length=100, \n",
    "                                            homology_dimensions=homology_dimensions, n_jobs=1)),\n",
    "    ('diagrams_scaler', diag.DiagramScaler()),\n",
    "    ('diagrams_filter', diag.DiagramFilter(delta=0.05))\n",
    "]\n",
    "\n",
    "pipeline_filter = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_filter.fit(X_noisy)\n",
    "X_filtered_noisy = pipeline_filter.transform(X_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "diagram = X_filtered_noisy[window_number]\n",
    "\n",
    "for dimension in homology_dimensions:\n",
    "    plt.plot(diagram[diagram[:,2] == dimension][:,0], \n",
    "             diagram[diagram[:,2] == dimension][:,1], 'o',label='homology '+ str(dimension))\n",
    "plt.title('Persistent Diagram')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1.5], [0, 1.5], color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent Entropy\n",
    "\n",
    "In this section we show how to compute the entropy of persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perparing the filtering transformer\n",
    "persistent_entropy = diag.PersistentEntropy()\n",
    "persistent_entropy.fit(X_scaled_noisy)\n",
    "X_persistent_entropy = persistent_entropy.transform(X_scaled_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_persistent_entropy)\n",
    "plt.title('Trajectory of the Lorenz solution, projected along the z-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances among diagrams\n",
    "\n",
    "In this section we show how to compute distances among persistent diagrams. There are many notions of distances: here we use the *bottleneck distance* as an example.\n",
    "\n",
    "We stress that the *i-th* row of this matrix is the distance of the *i-th* diagram from all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We change metric: we compute the landscape distance among the diagrams \n",
    "diagram_distance = diag.DiagramDistance(metric='landscape', metric_params={'p': 2, 'n_layers':1, 'n_values':1000}, \n",
    "                                       order=None, n_jobs=2)\n",
    "diagram_distance.fit(X_diagrams)\n",
    "X_distance_L = diagram_distance.transform(X_diagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the landascape L2 distance between persistent diagrams \n",
    "figure = plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_distance_L[:,:, 0])\n",
    "plt.colorbar()\n",
    "plt.title('Landscape L2 distance matrix for H0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We change metric: we compute the wasserestein distance among the diagrams \n",
    "diagram_distance = diag.DiagramDistance(metric='wasserstein', metric_params={'p': 2, 'delta':0.2}, \n",
    "                                       order=2, n_jobs=1)\n",
    "diagram_distance.fit(X_diagrams)\n",
    "X_distance_W = diagram_distance.transform(X_diagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the landascape L2 distance between persistent diagrams \n",
    "figure = plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_distance_W)\n",
    "plt.colorbar()\n",
    "plt.title('2-norm of 2-wassertein distance matrices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New distance in the embedding space: permutations and graphs\n",
    "\n",
    "We propose here a new way to compute distances between points in the embedding space. Instead of considering the Euclidean distance in the Takens space, we propose to build a k-nearest neightbors graph and then use the geodesic distance on such graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_graph = gr.KNeighborsGraph(n_neighbors=3, n_jobs=1)\n",
    "kNN_graph.fit(X_embedded)\n",
    "X_kNN = kNN_graph.transform(X_embedded[0].reshape((1, X_embedded.shape[1], -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodesic distance on graphs\n",
    "Given the graph embedding, the natural notion of distance between vertices corresponds to the lengths of the shortest path connecting two vertices. This is also known as *graph geodesic distance*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesic_distance = gr.GraphGeodesicDistance(n_jobs=1)\n",
    "geodesic_distance.fit(X_kNN)\n",
    "X_GeoNN = geodesic_distance.transform(X_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the geodesic distance\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_GeoNN[0])\n",
    "plt.colorbar()\n",
    "plt.title('Plot of the geodesic distance of the first outer window kNN graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic features extracted from topology\n",
    "\n",
    "One can use persistent diagrams as he pleases. Here we show one way of extracting summary information from the time-series of diagrams: the *permutation entropy*. The entropy is computed by estimating a probability based on teh counting how many permutation patterns appear along the time series within the outer window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing permutation entropy\n",
    "permutation_entropy = ts.PermutationEntropy(n_jobs=1)\n",
    "permutation_entropy.fit(X_windows)\n",
    "X_entropy = permutation_entropy.transform(X_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sampled Lorenz solution, projected along the z-axis\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_sampled)\n",
    "plt.title('Resampled solution of the Lorenz attractor projected along the z-axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the permutation entropy time-series\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "plt.plot(X_entropy)\n",
    "plt.title('Permutation entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing graph distances between the time series of graphs\n",
    "The procedure we have developed associateds to each outer window a graph. This graph is a subgraph of the full permutation graph. The distance among subgraphs is then defined via the geodesic distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_graph = gr.TransitionGraph(n_jobs=1)\n",
    "transition_graph.fit(X_windows)\n",
    "X_transition = transition_graph.transform(X_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing geodesic distance between subgraph inside the universal graph\n",
    "geodesic_distance = gr.GraphGeodesicDistance(n_jobs=1)\n",
    "geodesic_distance.fit(X_transition)\n",
    "X_geodesic = geodesic_distance.transform(X_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the geodesci distance between the time series of subgraphs\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_geodesic[window_number])\n",
    "plt.colorbar()\n",
    "plt.title('Geodesic graph distance between subgraphs.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
